{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Packages","metadata":{}},{"cell_type":"code","source":"import time, os, random\nfrom datetime import datetime\nfrom tqdm.notebook import tqdm\nfrom glob import glob\nfrom collections import OrderedDict\n\nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport cv2\nfrom sklearn.model_selection import train_test_split\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import transforms as T\nfrom torch.autograd import Variable\nfrom torch.utils.data import Dataset, DataLoader\nimport torchvision\nfrom torchsummary import summary\n\nimport albumentations as A\nimport segmentation_models_pytorch as smp\nimport urllib.request\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint('torch ver.', torch.__version__)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Parameters","metadata":{}},{"cell_type":"code","source":"IMAGE_PATH = '../input/original/' # Path to original image dir\nMASK_PATH = '../input/mask/' # Path to mask image dir\nPROXY_PIN = '../../PIN.txt' # [userID]:[passward]@[proxy server adrress]:[port number]\nN_CLASSES = 3 # Number of classes including background, i.e. N_CLASSES=2 for binary segmentation)\nBATCH_SIZE = 1\nSEED = 19","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Utilities","metadata":{}},{"cell_type":"code","source":"# Random seed\ndef seed_everything(seed=SEED):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\nseed_everything()\n\n# Proxy setting (to download encorder weigths of pretrained model) \ndef set_proxy(pin=PROXY_PIN):\n    with open(pin, 'r') as f:\n        proxy_pass = f.read()\n        proxies = {'http': 'http://' + proxy_pass, 'https': 'http://' + proxy_pass}\n    proxy = urllib.request.ProxyHandler(proxies)\n    opener = urllib.request.build_opener(proxy)\n    urllib.request.install_opener(opener)\nset_proxy()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"names = []\nfor dirname in glob(IMAGE_PATH + '*.jpg'):\n    filename = dirname.split('\\\\')[-1].split('.')[0]\n    names.append(filename)\ndf = pd.DataFrame({'id': names}, index=np.arange(0, len(names)))\ndf","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split data\nX_train_, X_test = train_test_split(df['id'].values, test_size=0.1, random_state=19)\nX_train, X_val = train_test_split(X_train_, test_size=0.2, random_state=19)\n\nprint('Train Size   : ', len(X_train))\nprint('Val Size     : ', len(X_val))\nprint('Test Size    : ', len(X_test))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Show sample data\nsamples = [0, 1, 2]\nfig, ax = plt.subplots(1, len(samples), figsize=(20, 5))\nfor i in samples:\n    img = cv2.imread(IMAGE_PATH + df['id'][i] + '.jpg')\n    mask = cv2.imread(MASK_PATH + df['id'][i] + '_mask.png', cv2.IMREAD_GRAYSCALE)\n    #print('Image Size', np.asarray(img).shape)\n    #print('Mask Size', np.asarray(mask).shape)\n    ax[i].imshow(img)\n    ax[i].imshow(mask*(255/np.max(mask)), cmap='jet', alpha=0.3)\n    ax[i].axis('off')\n    ax[i].set_title(df['id'][i])\nfig.suptitle('Original image with mas')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"class ImgMaskDataset(Dataset):\n    \n    def __init__(self, img_path, mask_path, X, mean, std, transform=None, patch=False):\n        self.img_path = img_path\n        self.mask_path = mask_path\n        self.X = X\n        self.transform = transform\n        self.patches = patch\n        self.mean = mean\n        self.std = std\n        \n    def __len__(self):\n        return len(self.X)\n    \n    def __getitem__(self, idx):\n        img = cv2.imread(self.img_path + self.X[idx] + '.jpg')\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        mask = cv2.imread(self.mask_path + self.X[idx] + '_mask.png', cv2.IMREAD_GRAYSCALE)\n        \n        if self.transform is not None:\n            aug = self.transform(image=img, mask=mask)\n            img = Image.fromarray(aug['image'])\n            mask = aug['mask']\n        \n        if self.transform is None:\n            img = Image.fromarray(img)\n        \n        t = T.Compose([T.ToTensor(), T.Normalize(self.mean, self.std)])\n        img = t(img)\n        mask = torch.from_numpy(mask).long()\n        \n        if self.patches:\n            img, mask = self.tiles(img, mask)\n            \n        return img, mask\n    \n    def tiles(self, img, mask):\n        img_patches = img.unfold(1, 512, 512).unfold(2, 768, 768) \n        img_patches  = img_patches.contiguous().view(3,-1, 512, 768)\n        img_patches = img_patches.permute(1,0,2,3)\n        mask_patches = mask.unfold(0, 512, 512).unfold(1, 768, 768)\n        mask_patches = mask_patches.contiguous().view(-1, 512, 768)\n        return img_patches, mask_patches\n        ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean =[0.485, 0.456, 0.406]\nstd = [0.229, 0.224, 0.225]\n\n# Transformer\nt_train = A.Compose([\n    A.Resize(704, 1056, interpolation=cv2.INTER_NEAREST),\n    A.HorizontalFlip(),\n    A.VerticalFlip(),\n    A.GridDistortion(p=0.2),\n    A.RandomBrightnessContrast((0, 0.5),(0, 0.5)),\n    A.GaussNoise()\n    ])\n\nt_val = A.Compose([\n    A.Resize(704, 1056, interpolation=cv2.INTER_NEAREST),\n    A.HorizontalFlip(),\n    A.GridDistortion(p=0.2)\n    ])\n\n# Dataset\ntrain_set = ImgMaskDataset(IMAGE_PATH, MASK_PATH, X_train, mean, std, t_train, patch=False)\nval_set = ImgMaskDataset(IMAGE_PATH, MASK_PATH, X_val, mean, std, t_val, patch=False)\n\n# Dataloader\ntrain_loader = DataLoader(train_set, BATCH_SIZE, shuffle=True)\nval_loader = DataLoader(val_set, BATCH_SIZE, shuffle=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"model = smp.Unet('efficientnet-b2', encoder_weights='imagenet', classes=N_CLASSES, activation=None, encoder_depth=5, decoder_channels=[256, 128, 64, 32, 16])\n# model = smp.Unet('resnet34', encoder_weights='imagenet', classes=N_CLASSES, activation=None, encoder_depth=5, decoder_channels=[256, 128, 64, 32, 16])\n# model = smp.Unet('mobilenet_v2', encoder_weights=None, classes=N_CLASSES, activation=None, encoder_depth=5, decoder_channels=[256, 128, 64, 32, 16])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Total params: ', sum(p.numel() for p in model.parameters()))\nprint('Trainable params:', sum(p.numel() for p in model.parameters() if p.requires_grad))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train","metadata":{}},{"cell_type":"code","source":"# Metrics\ndef pixel_accuracy(output, mask):\n    with torch.no_grad():\n        output = torch.argmax(F.softmax(output, dim=1), dim=1)\n        correct = torch.eq(output, mask).int()\n        accuracy = float(correct.sum()) / float(correct.numel())\n    return accuracy\n\n# IoU averaged over classes \ndef meanIoU(pred_mask, mask, smooth=1e-10, n_classes=N_CLASSES):\n    with torch.no_grad():\n        pred_mask = F.softmax(pred_mask, dim=1)\n        pred_mask = torch.argmax(pred_mask, dim=1)\n        pred_mask = pred_mask.contiguous().view(-1)\n        mask = mask.contiguous().view(-1)\n        iou_per_class = []\n        for c in range(n_classes):\n            pred_label = (pred_mask==c)\n            true_label = (mask==c)\n\n            if true_label.long().sum().item() == 0: # no exists label\n                iou_per_class.append(np.nan)\n            else:\n                intersect = torch.logical_and(pred_label, true_label).sum().float().item()\n                union = torch.logical_or(pred_label, true_label).sum().float().item()\n                iou = (intersect + smooth) / (union + smooth)\n                iou_per_class.append(iou)\n        \n        return np.nanmean(iou_per_class)\n\n# Dice coeffient average over classes \ndef meanDice(pred_mask, mask, smooth=1e-10, n_classes=N_CLASSES):\n    with torch.no_grad():\n        pred_mask = F.softmax(pred_mask, dim=1)\n        pred_mask = torch.argmax(pred_mask, dim=1)\n        pred_mask = pred_mask.contiguous().view(-1)\n        mask = mask.contiguous().view(-1)\n        dice_per_class = []\n        for c in range(n_classes):\n            pred_label = (pred_mask==c)\n            true_label = (mask==c)\n\n            if true_label.long().sum().item() == 0: # no exists label\n                dice_per_class.append(np.nan)\n            else:\n                intersect = torch.logical_and(pred_label, true_label).sum().float().item()\n                left = torch.sum(pred_label)\n                right = torch.sum(true_label)\n                dice = (2. * intersect + smooth) / (left + right + smooth)\n                dice_per_class.append(dice)\n\n        return np.nanmean(dice_per_class)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Learning rate\ndef get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group['lr']\n\n# Train\ndef fit(epochs, model, train_loader, val_loader, criterion, optimizer, scheduler, patch=False):\n    run_date = str(datetime.now().strftime(\"%Y%m%d-%H%M%S\"))                 \n    model_path = f'../model/model_{run_date}.pt' # trained model saved in\n    torch.cuda.empty_cache() # memory freeing\n    train_losses, val_losses  = [], []\n    train_iou, val_iou = [], []\n    train_dice, val_dice = [], []\n    train_acc, val_acc = [], []\n    lrs = []\n    min_loss = np.inf\n    decrease = 0\n    not_improve = 0\n    model.to(device)\n    \n    # Training\n    fit_start = time.time()\n    # # Loop per epochs\n    for e in range(epochs):\n        model.train()\n        epoch_start = time.time()\n        train_loss = 0\n        iou_score = 0\n        dice_score = 0\n        accuracy = 0\n        # # Loop per batch\n        with tqdm(train_loader) as pbar:\n            for i, data in enumerate(pbar):\n                pbar.set_description('[Epoch {:d} train]'.format(e + 1))\n                # Load input\n                image_tiles, mask_tiles = data\n                if patch:\n                    b, n_tiles, c, h, w = image_tiles.size()\n                    image_tiles = image_tiles.view(-1, c, h, w)\n                    mask_tiles = mask_tiles.view(-1, h, w)\n                image = image_tiles.to(device)\n                mask = mask_tiles.to(device)\n                # Forward\n                output = model(image)\n                loss = criterion(output, mask)\n                accuracy += pixel_accuracy(output, mask) \n                iou_score += meanIoU(output, mask)\n                dice_score += meanDice(output, mask)\n                # Backward\n                loss.backward() \n                optimizer.step() # update weigth\n                optimizer.zero_grad() # reset gradient\n                lrs.append(get_lr(optimizer))\n                scheduler.step()\n                train_loss += loss.item()\n                pbar.set_postfix(OrderedDict(dice=dice_score/(i+1)))\n        \n        # Validation\n        model.eval()\n        val_loss = 0\n        val_accuracy = 0\n        val_iou_score = 0\n        val_dice_score = 0\n        with torch.no_grad():\n            with tqdm(val_loader) as pbar:\n                for i, data in enumerate(pbar):\n                    pbar.set_description('[Epoch {:d} valid]'.format(e + 1))\n                    # Load input\n                    image_tiles, mask_tiles = data\n                    if patch:\n                        b, n_tiles, c, h, w = image_tiles.size()\n                        image_tiles = image_tiles.view(-1, c, h, w)\n                        mask_tiles = mask_tiles.view(-1, h, w)\n                    image = image_tiles.to(device)\n                    mask = mask_tiles.to(device)\n                    # Forward\n                    output = model(image)\n                    loss = criterion(output, mask)\n                    val_loss += loss.item()\n                    val_iou_score += meanIoU(output, mask)\n                    val_dice_score += meanDice(output, mask)\n                    val_accuracy += pixel_accuracy(output, mask)\n                    pbar.set_postfix(OrderedDict(dice=val_dice_score/(i+1)))\n        \n        # Metrics averaged in batch\n        train_losses.append(train_loss/len(train_loader))\n        val_losses.append(val_loss/len(val_loader))\n        \n        # Save model if loss updated\n        if min_loss > (val_loss / len(val_loader)):\n            # print('Loss decreasing...{:.3f} >> {:.3f}'.format(min_loss, (val_loss/len(val_loader))))\n            min_loss = val_loss / len(val_loader)\n            best_dice = val_dice_score / len(val_loader)\n            decrease += 1\n            not_improve = 0\n            if decrease >= 3:\n                # print('Saving model...')\n                torch.save(model, model_path)\n                \n        # Early stopping if loss not updated 3 times in succession\n        else:\n            not_improve += 1\n            print(f'Loss Not decrease for {not_improve} time')\n            if not_improve == 3:\n                print('Stop training since loss is not decreased for 3 times in succession')\n                break\n            \n        # Score\n        train_iou.append(iou_score / len(train_loader))\n        val_iou.append(val_iou_score / len(val_loader))\n        train_dice.append(dice_score / len(train_loader))\n        val_dice.append(val_dice_score / len(val_loader))\n        train_acc.append(accuracy / len(train_loader))\n        val_acc.append(val_accuracy / len(val_loader))\n        print('Epoch:{}/{} |'.format(e+1, epochs),\n        'Train Loss: {:.3f} |'.format(train_loss/len(train_loader)),\n        'Val Loss: {:.3f} |'.format(val_loss/len(val_loader)),\n        'Train Dice: {:.3f} |'.format(dice_score/len(train_loader)),\n        'Val Dice: {:.3f} |'.format(val_dice_score/len(val_loader)),\n        'Train Acc: {:.3f} |'.format(accuracy/len(train_loader)),\n        'Val Acc: {:.3f} |'.format(val_accuracy/len(val_loader)),\n#        'Train mIoU: {:.3f} |'.format(iou_score/len(train_loader)),\n#        'Val mIoU: {:.3f} |'.format(val_iou_score/len(val_loader)),\n        'Time: {:.2f} min.'.format((time.time()-epoch_start)/60))\n    \n    history = {'train_loss': train_losses, 'val_loss': val_losses,\n               'train_miou': train_iou, 'val_miou': val_iou,\n               'train_mdice': train_dice, 'val_mdice': val_dice,\n               'train_acc' : train_acc, 'val_acc': val_acc,\n               'lrs': lrs}\n    print('Total time: {:.2f} min.' .format((time.time() - fit_start)/60))\n    best_model_path = model_path.split('.pt')[0] + '_dice-{:.3f}'.format(best_dice) + '.pt'\n    os.rename(model_path, best_model_path)\n    if decrease<3:\n        print('Not model saved since training was not proceeding.')\n    else:\n        print(f'Model saved in {best_model_path}'\n\n    return history, best_model_path\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_lr = 1e-3\nepochs = 20\nweight_decay = 1e-4\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.AdamW(model.parameters(), lr=max_lr, weight_decay=weight_decay)\nscheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, steps_per_epoch=len(train_loader))\nhistory, model_path = fit(epochs, model, train_loader, val_loader, criterion, optimizer, scheduler)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Result","metadata":{}},{"cell_type":"code","source":"def plot_loss(history):\n    plt.plot( history['train_loss'], label='train', marker='o')\n    plt.plot(history['val_loss'], label='val', marker='o')\n    plt.title('Loss per epoch'); plt.ylabel('loss');\n    plt.xlabel('epoch')\n    plt.legend(), plt.grid()\n    plt.show()\n\n\ndef plot_iou(history):\n    plt.plot(history['train_miou'], label='train_mIoU', marker='*')\n    plt.plot(history['val_miou'], label='val_mIoU',  marker='*')\n    plt.title('Score per epoch'); plt.ylabel('mean IoU')\n    plt.xlabel('epoch')\n    plt.legend(), plt.grid()\n    plt.show()\n\ndef plot_dice(history):\n    plt.plot(history['train_mdice'], label='train_mdice', marker='*')\n    plt.plot(history['val_mdice'], label='val_mdice',  marker='*')\n    plt.title('Score per epoch'); plt.ylabel('mean dice')\n    plt.xlabel('epoch')\n    plt.legend(), plt.grid()\n    plt.show()\n\ndef plot_acc(history):\n    plt.plot(history['train_acc'], label='train_accuracy', marker='*')\n    plt.plot(history['val_acc'], label='val_accuracy',  marker='*')\n    plt.title('Accuracy per epoch'); plt.ylabel('Accuracy')\n    plt.xlabel('epoch')\n    plt.legend(), plt.grid()\n    plt.show()\n\nplot_loss(history)\nplot_dice(history)\nplot_acc(history)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"# Test dataset\nclass TestDataset(Dataset):\n\n    def __init__(self, img_path, mask_path, X, transform=None):\n        self.img_path = img_path\n        self.mask_path = mask_path\n        self.X = X\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.X)\n\n    def __getitem__(self, idx):\n        img = cv2.imread(self.img_path + self.X[idx] + '.jpg')\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        mask = cv2.imread(self.mask_path + self.X[idx] + '_mask.png', cv2.IMREAD_GRAYSCALE)\n\n        if self.transform is not None:\n            aug = self.transform(image=img, mask=mask)\n            img = Image.fromarray(aug['image'])\n            mask = aug['mask']\n\n        if self.transform is None:\n            img = Image.fromarray(img)\n        \n        mask = torch.from_numpy(mask).long()\n\n        return img, mask","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Score\ndef predict_dice(model, image, mask, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):\n    model.eval()\n    model.to(device)\n    t = T.Compose([T.ToTensor(), T.Normalize(mean, std)])\n    image = t(image)\n    image = image.to(device)\n    mask = mask.to(device)\n    with torch.no_grad():\n        image = image.unsqueeze(0)\n        mask = mask.unsqueeze(0)\n        output = model(image)\n        score = meanDice(output, mask)\n        masked = torch.argmax(output, dim=1)\n        masked = masked.cpu().squeeze(0)\n    return masked, score\n\ndef predict_acc(model, image, mask, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):\n    model.eval()\n    model.to(device)\n    t = T.Compose([T.ToTensor(), T.Normalize(mean, std)])\n    image = t(image)\n    image=image.to(device)\n    mask = mask.to(device)\n    with torch.no_grad():\n        image = image.unsqueeze(0)\n        mask = mask.unsqueeze(0)\n        output = model(image)\n        acc = pixel_accuracy(output, mask)\n        masked = torch.argmax(output, dim=1)\n        masked = masked.cpu().squeeze(0)\n    return masked, acc","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idx = 0\n# Load test data\nt_test = A.Resize(768, 1152, interpolation=cv2.INTER_NEAREST)\ntest_set = TestDataset(IMAGE_PATH, MASK_PATH, X_test, transform=t_test)\nimage, mask = test_set[idx]\n\n# Load model\nmodel = torch.load(model_path)\n# predict\npred_mask, score = predict_dice(model, image, mask)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, (ax1, ax2, ax3, ax4) = plt.subplots(1,4, figsize=(20,10))\nax1.imshow(image)\nax1.set_title(f'Original: {X_test[idx]}')\n\nax2.imshow(image)\nax2.imshow(mask, alpha=0.3, cmap='jet')\nax2.set_title('Origina with Ground truth')\nax2.set_axis_off()\n\nax3.imshow(mask, cmap='jet')\nax3.set_title('Ground truth')\nax3.set_axis_off()\n\nax4.imshow(pred_mask, cmap='jet')\nax4.set_title('Predict (Dice coff: {:.3f})'.format(score))\nax4.set_axis_off()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dice_score(model, test_set):\n    score_dice = []\n    for i in tqdm(range(len(test_set))):\n        img, mask = test_set[i]\n        pred_mask, score = predict_dice(model, img, mask)\n        score_dice.append(score)\n    return score_dice\n\ndef acc_score(model, test_set):\n    accuracy = []\n    for i in tqdm(range(len(test_set))):\n        img, mask = test_set[i]\n        pred_mask, acc = predict_acc(model, img, mask)\n        accuracy.append(acc)\n    return accuracy","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Average score for all test set","metadata":{}},{"cell_type":"code","source":"dice = dice_score(model, test_set)\nprint('Test Set mean dice {:.3f}'.format(np.mean(dice)))\nacc = acc_score(model, test_set)\nprint('Test set mean accuracy {:.3f}'.format(np.mean(acc)))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}