{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Packages"]},{"cell_type":"code","execution_count":2,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["torch ver. 1.11.0\n"]}],"source":["import time, os, random\n","from datetime import datetime\n","import tqdm\n","from glob import glob\n","from collections import OrderedDict\n","\n","import numpy as np \n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","import cv2\n","from sklearn.model_selection import train_test_split\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchvision import transforms as T\n","from torch.autograd import Variable\n","from torch.utils.data import Dataset, DataLoader\n","import torchvision\n","from torchsummary import summary\n","\n","import albumentations as A\n","import segmentation_models_pytorch as smp\n","import urllib.request\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print('torch ver.', torch.__version__)"]},{"cell_type":"markdown","metadata":{},"source":["# Parameters"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["IMAGE_PATH = '../input/original/' # Path to original image dir\n","MASK_PATH = '../input/mask/' # Path to mask image dir\n","PROXY_PIN = '../PIN.txt' # [userID]:[passward]@[proxy server adrress]:[port number]\n","N_CLASSES = 2 # Number of classes including background, i.e. N_CLASSES=2 for binary segmentation)\n","BATCH_SIZE = 1\n","SEED = 19"]},{"cell_type":"markdown","metadata":{},"source":["# Utilities"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# Random seed\n","def seed_everything(seed=SEED):\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","    np.random.seed(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = True\n","seed_everything()\n","\n","# Proxy setting (to download encorder weigths of pretrained model) \n","def set_proxy(pin=PROXY_PIN):\n","    with open(pin, 'r') as f:\n","        proxy_pass = f.read()\n","        proxies = {'http': 'http://' + proxy_pass, 'https': 'http://' + proxy_pass}\n","    proxy = urllib.request.ProxyHandler(proxies)\n","    opener = urllib.request.build_opener(proxy)\n","    urllib.request.install_opener(opener)\n","set_proxy()"]},{"cell_type":"markdown","metadata":{},"source":["# Data"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["Empty DataFrame\n","Columns: [id]\n","Index: []"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["names = []\n","for dirname in glob(IMAGE_PATH + '*.jpg'):\n","    filename = dirname.split('\\\\')[-1].split('.')[0]\n","    names.append(filename)\n","df = pd.DataFrame({'id': names}, index=np.arange(0, len(names)))\n","df"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"ename":"ValueError","evalue":"With n_samples=0, test_size=0.1 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/var/folders/jw/jbx4xg9x0vz1vgsjwppvrkhc0000gn/T/ipykernel_12449/2883218112.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Split data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_train_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m19\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m19\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Train Size   : '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/homebrew/anaconda3/envs/segmentation_3_7_11/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2419\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2420\u001b[0m     n_train, n_test = _validate_shuffle_split(\n\u001b[0;32m-> 2421\u001b[0;31m         \u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_test_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2422\u001b[0m     )\n\u001b[1;32m   2423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/homebrew/anaconda3/envs/segmentation_3_7_11/lib/python3.7/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   2099\u001b[0m             \u001b[0;34m\"With n_samples={}, test_size={} and train_size={}, the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m             \u001b[0;34m\"resulting train set will be empty. Adjust any of the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2101\u001b[0;31m             \u001b[0;34m\"aforementioned parameters.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2102\u001b[0m         )\n\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.1 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."]}],"source":["# Split data\n","X_train_, X_test = train_test_split(df['id'].values, test_size=0.1, random_state=19)\n","X_train, X_val = train_test_split(X_train_, test_size=0.2, random_state=19)\n","\n","print('Train Size   : ', len(X_train))\n","print('Val Size     : ', len(X_val))\n","print('Test Size    : ', len(X_test))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Show sample data\n","samples = [0, 1, 2]\n","fig, ax = plt.subplots(1, len(samples), figsize=(20, 5))\n","for i in samples:\n","    img = cv2.imread(IMAGE_PATH + df['id'][i] + '.jpg')\n","    mask = cv2.imread(MASK_PATH + df['id'][i] + '_mask.png', cv2.IMREAD_GRAYSCALE)\n","    # print('Image Size', np.asarray(img).shape)\n","    # print('Mask Size', np.asarray(mask).shape)\n","    ax[i].imshow(img)\n","    ax[i].imshow(mask*(255/np.max(mask)), cmap='jet', alpha=0.3)\n","    ax[i].axis('off')\n","    ax[i].set_title(df['id'][i])\n","fig.suptitle('Original image with mas')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class ImgMaskDataset(Dataset):\n","    \n","    def __init__(self, img_path, mask_path, X, mean, std, transform=None, patch=False):\n","        self.img_path = img_path\n","        self.mask_path = mask_path\n","        self.X = X\n","        self.transform = transform\n","        self.patches = patch\n","        self.mean = mean\n","        self.std = std\n","        \n","    def __len__(self):\n","        return len(self.X)\n","    \n","    def __getitem__(self, idx):\n","        img = cv2.imread(self.img_path + self.X[idx] + '.jpg')\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","        mask = cv2.imread(self.mask_path + self.X[idx] + '_mask.png', cv2.IMREAD_GRAYSCALE)\n","        \n","        if self.transform is not None:\n","            aug = self.transform(image=img, mask=mask)\n","            img = Image.fromarray(aug['image'])\n","            mask = aug['mask']\n","        \n","        if self.transform is None:\n","            img = Image.fromarray(img)\n","        \n","        t = T.Compose([T.ToTensor(), T.Normalize(self.mean, self.std)])\n","        img = t(img)\n","        mask = torch.from_numpy(mask).long()\n","        \n","        if self.patches:\n","            img, mask = self.tiles(img, mask)\n","            \n","        return img, mask\n","    \n","    def tiles(self, img, mask):\n","        img_patches = img.unfold(1, 512, 512).unfold(2, 768, 768) \n","        img_patches  = img_patches.contiguous().view(3,-1, 512, 768)\n","        img_patches = img_patches.permute(1,0,2,3)\n","        mask_patches = mask.unfold(0, 512, 512).unfold(1, 768, 768)\n","        mask_patches = mask_patches.contiguous().view(-1, 512, 768)\n","        return img_patches, mask_patches\n","        "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["mean =[0.485, 0.456, 0.406]\n","std = [0.229, 0.224, 0.225]\n","\n","# Transformer\n","t_train = A.Compose([\n","    A.Resize(704, 1056, interpolation=cv2.INTER_NEAREST),\n","    A.HorizontalFlip(),\n","    A.VerticalFlip(),\n","    A.GridDistortion(p=0.2),\n","    A.RandomBrightnessContrast((0, 0.5),(0, 0.5)),\n","    A.GaussNoise()\n","    ])\n","\n","t_val = A.Compose([\n","    A.Resize(704, 1056, interpolation=cv2.INTER_NEAREST),\n","    A.HorizontalFlip(),\n","    A.GridDistortion(p=0.2)\n","    ])\n","\n","# Dataset\n","train_set = ImgMaskDataset(IMAGE_PATH, MASK_PATH, X_train, mean, std, t_train, patch=False)\n","val_set = ImgMaskDataset(IMAGE_PATH, MASK_PATH, X_val, mean, std, t_val, patch=False)\n","\n","# Dataloader\n","train_loader = DataLoader(train_set, BATCH_SIZE, shuffle=True)\n","val_loader = DataLoader(val_set, BATCH_SIZE, shuffle=True)"]},{"cell_type":"markdown","metadata":{},"source":["# Model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model = smp.Unet('efficientnet-b2', encoder_weights='imagenet', classes=N_CLASSES, activation=None, encoder_depth=5, decoder_channels=[256, 128, 64, 32, 16])\n","# model = smp.Unet('resnet34', encoder_weights='imagenet', classes=N_CLASSES, activation=None, encoder_depth=5, decoder_channels=[256, 128, 64, 32, 16])\n","# model = smp.Unet('mobilenet_v2', encoder_weights=None, classes=N_CLASSES, activation=None, encoder_depth=5, decoder_channels=[256, 128, 64, 32, 16])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print('Total params: ', sum(p.numel() for p in model.parameters()))\n","print('Trainable params:', sum(p.numel() for p in model.parameters() if p.requires_grad))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["# Train"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Metrics\n","def pixel_accuracy(output, mask):\n","    with torch.no_grad():\n","        output = torch.argmax(F.softmax(output, dim=1), dim=1)\n","        correct = torch.eq(output, mask).int()\n","        accuracy = float(correct.sum()) / float(correct.numel())\n","    return accuracy\n","\n","# IoU averaged over classes \n","def meanIoU(pred_mask, mask, smooth=1e-10, n_classes=N_CLASSES):\n","    with torch.no_grad():\n","        pred_mask = F.softmax(pred_mask, dim=1)\n","        pred_mask = torch.argmax(pred_mask, dim=1)\n","        pred_mask = pred_mask.contiguous().view(-1)\n","        mask = mask.contiguous().view(-1)\n","        iou_per_class = []\n","        for c in range(n_classes):\n","            pred_label = (pred_mask==c)\n","            true_label = (mask==c)\n","\n","            if true_label.long().sum().item() == 0: # no exists label\n","                iou_per_class.append(np.nan)\n","            else:\n","                intersect = torch.logical_and(pred_label, true_label).sum().float().item()\n","                union = torch.logical_or(pred_label, true_label).sum().float().item()\n","                iou = (intersect + smooth) / (union + smooth)\n","                iou_per_class.append(iou)\n","        \n","        return np.nanmean(iou_per_class)\n","\n","# Dice coeffient average over classes \n","def meanDice(pred_mask, mask, smooth=1e-10, n_classes=N_CLASSES):\n","    with torch.no_grad():\n","        pred_mask = F.softmax(pred_mask, dim=1)\n","        pred_mask = torch.argmax(pred_mask, dim=1)\n","        pred_mask = pred_mask.contiguous().view(-1)\n","        mask = mask.contiguous().view(-1)\n","        dice_per_class = []\n","        for c in range(n_classes):\n","            pred_label = (pred_mask==c)\n","            true_label = (mask==c)\n","\n","            if true_label.long().sum().item() == 0: # no exists label\n","                dice_per_class.append(np.nan)\n","            else:\n","                intersect = torch.logical_and(pred_label, true_label).sum().float().item()\n","                left = torch.sum(pred_label)\n","                right = torch.sum(true_label)\n","                dice = (2. * intersect + smooth) / (left + right + smooth)\n","                dice_per_class.append(dice)\n","\n","        return np.nanmean(dice_per_class)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Learning rate\n","def get_lr(optimizer):\n","    for param_group in optimizer.param_groups:\n","        return param_group['lr']\n","\n","# Train\n","def fit(epochs, model, train_loader, val_loader, criterion, optimizer, scheduler, patch=False):\n","    run_date = str(datetime.now().strftime(\"%Y%m%d-%H%M%S\"))                 \n","    model_path = f'../model/model_{run_date}.pt' # trained model saved in\n","    torch.cuda.empty_cache() # memory freeing\n","    train_losses, val_losses  = [], []\n","    train_iou, val_iou = [], []\n","    train_dice, val_dice = [], []\n","    train_acc, val_acc = [], []\n","    lrs = []\n","    min_loss = np.inf\n","    decrease = 0\n","    not_improve = 0\n","    model.to(device)\n","    \n","    # Training\n","    fit_start = time.time()\n","    # # Loop per epochs\n","    for e in range(epochs):\n","        model.train()\n","        epoch_start = time.time()\n","        train_loss = 0\n","        iou_score = 0\n","        dice_score = 0\n","        accuracy = 0\n","        # # Loop per batch\n","        with tqdm(train_loader) as pbar:\n","            for i, data in enumerate(pbar):\n","                pbar.set_description('[Epoch {:d} train]'.format(e + 1))\n","                # Load input\n","                image_tiles, mask_tiles = data\n","                if patch:\n","                    b, n_tiles, c, h, w = image_tiles.size()\n","                    image_tiles = image_tiles.view(-1, c, h, w)\n","                    mask_tiles = mask_tiles.view(-1, h, w)\n","                image = image_tiles.to(device)\n","                mask = mask_tiles.to(device)\n","                # Forward\n","                output = model(image)\n","                loss = criterion(output, mask)\n","                accuracy += pixel_accuracy(output, mask) \n","                iou_score += meanIoU(output, mask)\n","                dice_score += meanDice(output, mask)\n","                # Backward\n","                loss.backward() \n","                optimizer.step() # update weigth\n","                optimizer.zero_grad() # reset gradient\n","                lrs.append(get_lr(optimizer))\n","                scheduler.step()\n","                train_loss += loss.item()\n","                pbar.set_postfix(OrderedDict(dice=dice_score/(i+1)))\n","        \n","        # Validation\n","        model.eval()\n","        val_loss = 0\n","        val_accuracy = 0\n","        val_iou_score = 0\n","        val_dice_score = 0\n","        with torch.no_grad():\n","            with tqdm(val_loader) as pbar:\n","                for i, data in enumerate(pbar):\n","                    pbar.set_description('[Epoch {:d} valid]'.format(e + 1))\n","                    # Load input\n","                    image_tiles, mask_tiles = data\n","                    if patch:\n","                        b, n_tiles, c, h, w = image_tiles.size()\n","                        image_tiles = image_tiles.view(-1, c, h, w)\n","                        mask_tiles = mask_tiles.view(-1, h, w)\n","                    image = image_tiles.to(device)\n","                    mask = mask_tiles.to(device)\n","                    # Forward\n","                    output = model(image)\n","                    loss = criterion(output, mask)\n","                    val_loss += loss.item()\n","                    val_iou_score += meanIoU(output, mask)\n","                    val_dice_score += meanDice(output, mask)\n","                    val_accuracy += pixel_accuracy(output, mask)\n","                    pbar.set_postfix(OrderedDict(dice=val_dice_score/(i+1)))\n","        \n","        # Metrics averaged in batch\n","        train_losses.append(train_loss/len(train_loader))\n","        val_losses.append(val_loss/len(val_loader))\n","        \n","        # Save model if loss updated\n","        if min_loss > (val_loss / len(val_loader)):\n","            # print('Loss decreasing...{:.3f} >> {:.3f}'.format(min_loss, (val_loss/len(val_loader))))\n","            min_loss = val_loss / len(val_loader)\n","            best_dice = val_dice_score / len(val_loader)\n","            decrease += 1\n","            not_improve = 0\n","            if decrease >= 3:\n","                # print('Saving model...')\n","                torch.save(model, model_path)\n","                \n","        # Early stopping if loss not updated 3 times in succession\n","        else:\n","            not_improve += 1\n","            print(f'Loss Not decrease for {not_improve} time')\n","            if not_improve == 3:\n","                print('Stop training since loss is not decreased for 3 times in succession')\n","                break\n","            \n","        # Score\n","        train_iou.append(iou_score / len(train_loader))\n","        val_iou.append(val_iou_score / len(val_loader))\n","        train_dice.append(dice_score / len(train_loader))\n","        val_dice.append(val_dice_score / len(val_loader))\n","        train_acc.append(accuracy / len(train_loader))\n","        val_acc.append(val_accuracy / len(val_loader))\n","        print('Epoch:{}/{} |'.format(e+1, epochs),\n","        'Train Loss: {:.3f} |'.format(train_loss/len(train_loader)),\n","        'Val Loss: {:.3f} |'.format(val_loss/len(val_loader)),\n","        'Train Dice: {:.3f} |'.format(dice_score/len(train_loader)),\n","        'Val Dice: {:.3f} |'.format(val_dice_score/len(val_loader)),\n","        'Train Acc: {:.3f} |'.format(accuracy/len(train_loader)),\n","        'Val Acc: {:.3f} |'.format(val_accuracy/len(val_loader)),\n","#        'Train mIoU: {:.3f} |'.format(iou_score/len(train_loader)),\n","#        'Val mIoU: {:.3f} |'.format(val_iou_score/len(val_loader)),\n","        'Time: {:.2f} min.'.format((time.time()-epoch_start)/60))\n","    \n","    history = {'train_loss': train_losses, 'val_loss': val_losses,\n","               'train_miou': train_iou, 'val_miou': val_iou,\n","               'train_mdice': train_dice, 'val_mdice': val_dice,\n","               'train_acc' : train_acc, 'val_acc': val_acc,\n","               'lrs': lrs}\n","    print('Total time: {:.2f} min.' .format((time.time() - fit_start)/60))\n","    best_model_path = model_path.split('.pt')[0] + '_dice-{:.3f}'.format(best_dice) + '.pt'\n","    os.rename(model_path, best_model_path)\n","    if decrease<3:\n","        print('Not model saved since training was not proceeding.')\n","    else:\n","        print(f'Model saved in {best_model_path}'\n","\n","    return history, best_model_path\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["max_lr = 1e-3\n","epochs = 20\n","weight_decay = 1e-4\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.AdamW(model.parameters(), lr=max_lr, weight_decay=weight_decay)\n","scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, steps_per_epoch=len(train_loader))\n","history, model_path = fit(epochs, model, train_loader, val_loader, criterion, optimizer, scheduler)"]},{"cell_type":"markdown","metadata":{},"source":["# Result"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def plot_loss(history):\n","    plt.plot( history['train_loss'], label='train', marker='o')\n","    plt.plot(history['val_loss'], label='val', marker='o')\n","    plt.title('Loss per epoch'); plt.ylabel('loss');\n","    plt.xlabel('epoch')\n","    plt.legend(), plt.grid()\n","    plt.show()\n","\n","\n","def plot_iou(history):\n","    plt.plot(history['train_miou'], label='train_mIoU', marker='*')\n","    plt.plot(history['val_miou'], label='val_mIoU',  marker='*')\n","    plt.title('Score per epoch'); plt.ylabel('mean IoU')\n","    plt.xlabel('epoch')\n","    plt.legend(), plt.grid()\n","    plt.show()\n","\n","def plot_dice(history):\n","    plt.plot(history['train_mdice'], label='train_mdice', marker='*')\n","    plt.plot(history['val_mdice'], label='val_mdice',  marker='*')\n","    plt.title('Score per epoch'); plt.ylabel('mean dice')\n","    plt.xlabel('epoch')\n","    plt.legend(), plt.grid()\n","    plt.show()\n","\n","def plot_acc(history):\n","    plt.plot(history['train_acc'], label='train_accuracy', marker='*')\n","    plt.plot(history['val_acc'], label='val_accuracy',  marker='*')\n","    plt.title('Accuracy per epoch'); plt.ylabel('Accuracy')\n","    plt.xlabel('epoch')\n","    plt.legend(), plt.grid()\n","    plt.show()\n","\n","plot_loss(history)\n","plot_dice(history)\n","plot_acc(history)"]},{"cell_type":"markdown","metadata":{},"source":["# Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Test dataset\n","class TestDataset(Dataset):\n","\n","    def __init__(self, img_path, mask_path, X, transform=None):\n","        self.img_path = img_path\n","        self.mask_path = mask_path\n","        self.X = X\n","        self.transform = transform\n","    \n","    def __len__(self):\n","        return len(self.X)\n","\n","    def __getitem__(self, idx):\n","        img = cv2.imread(self.img_path + self.X[idx] + '.jpg')\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","        mask = cv2.imread(self.mask_path + self.X[idx] + '_mask.png', cv2.IMREAD_GRAYSCALE)\n","\n","        if self.transform is not None:\n","            aug = self.transform(image=img, mask=mask)\n","            img = Image.fromarray(aug['image'])\n","            mask = aug['mask']\n","\n","        if self.transform is None:\n","            img = Image.fromarray(img)\n","        \n","        mask = torch.from_numpy(mask).long()\n","\n","        return img, mask"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Score\n","def predict_dice(model, image, mask, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):\n","    model.eval()\n","    model.to(device)\n","    t = T.Compose([T.ToTensor(), T.Normalize(mean, std)])\n","    image = t(image)\n","    image = image.to(device)\n","    mask = mask.to(device)\n","    with torch.no_grad():\n","        image = image.unsqueeze(0)\n","        mask = mask.unsqueeze(0)\n","        output = model(image)\n","        score = meanDice(output, mask)\n","        masked = torch.argmax(output, dim=1)\n","        masked = masked.cpu().squeeze(0)\n","    return masked, score\n","\n","def predict_acc(model, image, mask, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]):\n","    model.eval()\n","    model.to(device)\n","    t = T.Compose([T.ToTensor(), T.Normalize(mean, std)])\n","    image = t(image)\n","    image=image.to(device)\n","    mask = mask.to(device)\n","    with torch.no_grad():\n","        image = image.unsqueeze(0)\n","        mask = mask.unsqueeze(0)\n","        output = model(image)\n","        acc = pixel_accuracy(output, mask)\n","        masked = torch.argmax(output, dim=1)\n","        masked = masked.cpu().squeeze(0)\n","    return masked, acc"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["idx = 0\n","# Load test data\n","t_test = A.Resize(768, 1152, interpolation=cv2.INTER_NEAREST)\n","test_set = TestDataset(IMAGE_PATH, MASK_PATH, X_test, transform=t_test)\n","image, mask = test_set[idx]\n","\n","# Load model\n","model = torch.load(model_path)\n","# predict\n","pred_mask, score = predict_dice(model, image, mask)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["fig, (ax1, ax2, ax3, ax4) = plt.subplots(1,4, figsize=(20,10))\n","ax1.imshow(image)\n","ax1.set_title(f'Original: {X_test[idx]}')\n","\n","ax2.imshow(image)\n","ax2.imshow(mask, alpha=0.3, cmap='jet')\n","ax2.set_title('Origina with Ground truth')\n","ax2.set_axis_off()\n","\n","ax3.imshow(mask, cmap='jet')\n","ax3.set_title('Ground truth')\n","ax3.set_axis_off()\n","\n","ax4.imshow(pred_mask, cmap='jet')\n","ax4.set_title('Predict (Dice coff: {:.3f})'.format(score))\n","ax4.set_axis_off()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def dice_score(model, test_set):\n","    score_dice = []\n","    for i in tqdm(range(len(test_set))):\n","        img, mask = test_set[i]\n","        pred_mask, score = predict_dice(model, img, mask)\n","        score_dice.append(score)\n","    return score_dice\n","\n","def acc_score(model, test_set):\n","    accuracy = []\n","    for i in tqdm(range(len(test_set))):\n","        img, mask = test_set[i]\n","        pred_mask, acc = predict_acc(model, img, mask)\n","        accuracy.append(acc)\n","    return accuracy"]},{"cell_type":"markdown","metadata":{},"source":["## Average score for all test set"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["dice = dice_score(model, test_set)\n","print('Test Set mean dice {:.3f}'.format(np.mean(dice)))\n","acc = acc_score(model, test_set)\n","print('Test set mean accuracy {:.3f}'.format(np.mean(acc)))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.11"}},"nbformat":4,"nbformat_minor":4}
